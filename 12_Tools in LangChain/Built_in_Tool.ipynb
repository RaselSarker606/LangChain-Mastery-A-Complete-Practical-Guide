{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Built-in Tool"
      ],
      "metadata": {
        "id": "aPA-1muQCH0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-community wikipedia duckduckgo-search wikipedia sqlalchemy requests google-auth google-auth-oauthlib google-api-python-client pydantic langchain_experimental"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS_UHRbg2vbD",
        "outputId": "99cc2981-7f0a-44d3-c5a8-321454a91376"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.65)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.0.4-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.172.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.14.0)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-8.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=4ad14391deed7b5fdddc59a639ae60ce132e7faa594b25d8018cfbbe84723c19\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: python-dotenv, primp, mypy-extensions, marshmallow, httpx-sse, wikipedia, typing-inspect, duckduckgo-search, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community, langchain_experimental\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.65\n",
            "    Uninstalling langchain-core-0.3.65:\n",
            "      Successfully uninstalled langchain-core-0.3.65\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "Successfully installed dataclasses-json-0.6.7 duckduckgo-search-8.0.4 httpx-sse-0.4.0 langchain-0.3.26 langchain-community-0.3.26 langchain-core-0.3.66 langchain_experimental-0.3.4 marshmallow-3.26.1 mypy-extensions-1.1.0 primp-0.15.0 pydantic-settings-2.10.0 python-dotenv-1.1.0 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DuckDuckGo Search"
      ],
      "metadata": {
        "id": "wbWjHaPjV2Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "Duck_tool = DuckDuckGoSearchRun()\n",
        "\n",
        "results = Duck_tool.invoke('top news in Bangladesh today')\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "42L2d7ZyV19L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fd3860-f10d-43bf-cca1-4f4de158c102"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today's news of The Daily Star at a glance. To know today's all the latest news of The Daily Star, visit our top news page. Get today's news, all news, today's headlines, today's national news ... Stay on top of Bangladesh latest developments on the ground with Al Jazeera's fact-based news, exclusive video footage, photos and updated maps. Stay current with all the latest and breaking news about Bangladesh, compare headlines and perspectives between news sources on stories happening today. In total, 3,042stories have been published about Bangladesh which Ground News has aggregated in the past 3 months. Today's news list; Press Releases; Videos more. TOP NEWS. Dhaka, Delhi ties forged through shared experiences, sacrifices: India. Fakhrul to lead BNP delegation to China from Sunday. ... United News of Bangladesh (UNB) Cosmos Centre 69/1 New Circular Road, Malibagh, Dhaka-1217,Bangladesh. ... Zubaida Rahman's birthday today. 1 day ago. 6 burned as building collapses in Ashulia gas leak explosion. 1 day ago. Khaleda Zia to visit Evercare Hospital today. 1 day ago. NCC holds third day of talks with political parties today. 1 day ago. Tom Cruise to receive honorary Oscar in career first. 1 day ago. India pushes 20 more into Bangladesh ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Duck_tool.name)\n",
        "print(Duck_tool.description)\n",
        "print(Duck_tool.args)"
      ],
      "metadata": {
        "id": "FeSrojLMWCCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc4b75f-1428-46a3-a028-893d1be33c35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duckduckgo_search\n",
            "A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "{'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Shell Tool"
      ],
      "metadata": {
        "id": "26Egm-E8WMAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import ShellTool\n",
        "\n",
        "shell_tool = ShellTool()\n",
        "\n",
        "results = shell_tool.invoke('echo Hello from ShellTool')\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "x2XWMgMbWQn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ef1544-c624-403f-dd0e-93ec00da0b72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing command:\n",
            " echo Hello from ShellTool\n",
            "Hello from ShellTool\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shell_tool.name)\n",
        "print(shell_tool.description)\n",
        "print(shell_tool.args)"
      ],
      "metadata": {
        "id": "Qw5l1p0RWm3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ebc806-e331-4c6c-c384-afcf086b397c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "terminal\n",
            "Run shell commands on this Linux machine.\n",
            "{'commands': {'anyOf': [{'type': 'string'}, {'items': {'type': 'string'}, 'type': 'array'}], 'description': 'List of shell commands to run. Deserialized using json.loads', 'title': 'Commands'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Wikipedia Query Tool"
      ],
      "metadata": {
        "id": "LnzaYy49yc84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "# Initialize the Wikipedia API wrapper\n",
        "wikipedia_api_wrapper = WikipediaAPIWrapper()\n",
        "\n",
        "# Initialize the WikipediaQueryRun tool with the API wrapper\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)\n",
        "\n",
        "# Example: Searching for a topic\n",
        "result = wiki_tool.invoke(\"What is Artificial Intelligence\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtsJ_sXA0n-j",
        "outputId": "48770820-cc89-4dab-f769-8cbd7c119ca8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, while raising ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
            "\n",
            "\n",
            "\n",
            "Page: Artificial general intelligence\n",
            "Summary: Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\n",
            "Some researchers argue that state‑of‑the‑art large language models already exhibit early signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. AGI is conceptually distinct from artificial superintelligence (ASI), which would outperform the best human abilities across every domain by a wide margin. AGI is considered one of the definitions of strong AI.\n",
            "Unlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\n",
            "Creating AGI is a primary go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool.name)\n",
        "print(wiki_tool.description)\n",
        "print(wiki_tool.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIKbMiFN5wZP",
        "outputId": "b7206eea-7266-4490-fb09-73b63ee9ef22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wikipedia\n",
            "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
            "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Request Get Tool"
      ],
      "metadata": {
        "id": "sSFZVeWLy4k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import RequestsGetTool\n",
        "from langchain_community.utilities import RequestsWrapper\n",
        "\n",
        "get_tool = RequestsGetTool(requests_wrapper=RequestsWrapper(), allow_dangerous_requests=True)\n",
        "\n",
        "# Example: Send a GET request to a URL\n",
        "result = get_tool.invoke({\"url\": \"https://fojik.com/\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNro50Yf0vP4",
        "outputId": "8a134b7a-9c68-4491-93e1-ddfbde71d4cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html><html lang=\"en-US\"><head><title>Just a moment...</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"><meta name=\"robots\" content=\"noindex,nofollow\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"><style>*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width <= 720px){.main-content{margin-top:4rem}}.h2{font-size:1.5rem;font-weight:500;line-height:2.25rem}@media (width <= 720px){.h2{font-size:1.25rem;line-height:1.5rem}}#challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+);background-repeat:no-repeat;background-size:contain;padding-left:34px}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}}</style><meta http-equiv=\"refresh\" content=\"360\"></head><body><div class=\"main-wrapper\" role=\"main\"><div class=\"main-content\"><noscript><div class=\"h2\"><span id=\"challenge-error-text\">Enable JavaScript and cookies to continue</span></div></noscript></div></div><script>(function(){window._cf_chl_opt={cvId: '3',cZone: \"fojik.com\",cType: 'interactive',cRay: '9535653b9f3278cb',cH: 'Ib7H19UWnN6Y2i3uubmGwIPFvmUf1AvEVPQq.rDJ7rM-1750528721-1.2.1.1-8nGYK_cFDeAWniHjJ11N.WwlWrOtZk8GMcP.r2kfHlJ2sVgovSjM7u8c38QuIyyh',cUPMDTk: \"\\/?__cf_chl_tk=kbpM5X7ba50puBc4V2DHezLh0Y3sTJ5W1wD66OZ9OH0-1750528721-1.0.1.1-kAL4jdSN_E1befPgdrK6xLbOQobq8l2sqRJLub_1WA4\",cFPWv: 'g',cITimeS: '1750528721',cTplC: 0,cTplV: 5,cTplB: 'cf',fa: \"\\/?__cf_chl_f_tk=kbpM5X7ba50puBc4V2DHezLh0Y3sTJ5W1wD66OZ9OH0-1750528721-1.0.1.1-kAL4jdSN_E1befPgdrK6xLbOQobq8l2sqRJLub_1WA4\",md: \".yzBs2ULLRHgkHIqFXVNiBYwgEBSwFwV.Mqp_o7Lar4-1750528721-1.2.1.1-qxpscXy2lfhuv_Erkm2ZXTO4R9UvBuuCfJxDMXU9J2Y7J_Pj.pyDwNgg08wvERpwHg07iz788o8qE3XHHYWbETwOwV6xuXTUzzStwqwyUF8XZRXuE_S19GUmrx_5gITP4wbI7AI4vAz.0YweQg0bgEV41swbBTlamZJDhnmqN4VKCSX0eC9Yb_OnQps3MQW5ElWHyky0IADe5FDxbe4B6gfrKBjbnThP6zibZjAs.VVmM.zZi2mpviVEtGfrUs4zauZOM.s8Wcfw2_CFXBKSELSuR6zlVYYtJ_aLtVHuc3O3xD5uZ_Gije8.lNSJGztfTlJOkKaQpUvfQ2xoO45.VvHHvtQKt79QWB0ov5sY6FOaQXn4oSeTf2tRrauXao4C8mnSvEI6ZsXAvi8QuCd6iX0ixx7zQNX.Fzd6f.7LyJzDykXLRtHEMDFheSn0dBSuG_OmI8XitphsusvmEM.k5kCA13GF2Lilmyk6IoagcDPowH4sFRb736IPmC6eCdPQzn91FkUzGatoB96GDT23CWEMHC9sapyuOPYRMg81pNvMxrTgpyXSlrwGr6IPD642tAeD.910YSpXodd7vFqiEq5kIk2gxfhlg7kkFe_YZyo3QLkrWFigsbo7E5cE6dGAJ6bShq9jnezbRq2qKZc.ceNoblzzCggnD7CzG7JeaRPeD6P6T52Tpu29E2r1aNUv49nCMA0Adg51E9x0zUnq6ADI0VFNmOURQAGfFDNhxM4Ky_Keg5_QWja4tU6unyYFLfOF1HoqTt6n8W2KM1l9eEFID2C5uJPg5fAJCT_DsBk\",mdrd: \"kqIV2BGElvdVC5zs5i.uZSBs0V9Oe_X2MIU5.W2D3yg-1750528721-1.2.1.1-wERTv0v2X2vUWmFdWJ8ed70Xunsbt125gKsxhSpCj95vsd5f.eZJ5ZASx0pc.m.z5S5q31Tsasr7ZzvjsggsWqMrM7OQTqKuWOvM0KJBMLo3wI_I0YdF3wBrVm7vUtxzHpah6qC0PAoRWU1NCQ6Fr5ZbCx7t_M9BXeiN_Y5B9r.nBB96hyurSYj5wkt53jx0Bes0FCN6k0eYno5pF.mYu4Zi1w6SARtnpcGP7htvTWxKuU7hMlJy3H_MTQwjju.p4mjmOn03yo1EIdkEWrS5n9wMEzLR573bFLUxoEe34qKMMRS.vArMBg3.tMOKuX9lXIcuLX02C1c_KA4Jm1kFco.JxaASOxt0N3f0plElQLX7LtWMn26fdNOejcRFQpkosH.G5H29t.Fvq40PSAlrJuFTIOI0k8RO.Edlrl94Y75CqxMX.CJxgr2AG2o2h0jK6M8NL4TAgUXndu9RdyoOZID5afPpyOPfVW4jB27qv8AwYsLXrU_dqK57._.GXlY3OcQu.iqg3o5b4.Ntmos_wCJLiV9lcFZXF8l0R45r74QTqrFpZuaIrCeN9GYV4ZfJG2RvF_vPZdo0KjJ1B3JN6vzB7sQFPTifM8To.A6DQkCwu4paQUR4Ex75AvLeDG8fosNWnInYPmfsnm_6K9GK3ExNYubEag9oLaFS478MAQlGe5zIDEgnBnILN1Y7rFil_FptxKecPcNbPZbW.268LKHI.q8kbP4i4541yv7K3tybYJcSZ9ZGYwY43MxnAHzkZTkTwf69pyaN1xshH2PV_Mw.OkDZK4HdMexcfpIIavlgjXBT0uaOWNVvOEH9e3SYF9dX_VDsat2J9O.ymCT9wYXpIk._.6.f54PnCuWVQ5RpMTlfH14O984U1u6y4hJo.iW2LbiYSo2PRerocOCIaMJqvR07Wsn3QvPurcaIWqQd96GAaHJStO3pqtxPOu4Kz2JF69JDlxR1jdcAzEKbkRw_ldmpry5yRB20GXU8IlLPv24BuuXvPl2fDBm9r8r6PIV7DR18krgVq7jPA8h.ruXYtCjjPF0dXmyBqCXX0jW4VzzBtIhPvVYvdp8lt1ad9DV7T4wxj.Rb0yKePrDOfeVKfW366DUw_V95baSOPyxqsAENd0jBQNS7x8yW1FZNj0xZaCJeLzx8JfnRyFpuKeetXf_Up8ejrwgToo6Z.ikiH7QptBsvZux_22OGCWiDuf1bSMFd_jMQzPfEEd40roVC6tj5Hdj7GtJ8xjpq2XQEk.KfrIf7AYiuTvrM80yS2yEOcOneNcmkoYt.kR_1Hga9YCTXHgEqdUarabbenXRQjSihSQM44VpRLxTLWKwAhu4RVFU6PhrpWNHX0zjqAdGV71LXghiVmwNkg8lbL_._7mEVydhir9A8MsAicbA.JPVcBF3BKi4n2KXEhC7qqjwJlYdCJ06Vd2PiZ2pNx_cQywc6J1CUYOct3ZUgmKA6ebV0wYYZmGmj8IvK5OR5vsVEkcw0CeDed7uS7IdvvT2I1FSG581J_t54CdSqm1wpaShnxvI_x4XoJJtyROPjhiqWJ6_h3SlMzTe_7UPdtR1Gr7GfQDc14z9OMzSs_dKSwK1rXPwGjOunsHAFkjw5o6e_tBQbcLQaRThXUagpBDQUP9VsaE4RLEM3OuNmYtycQlv8X4OFgKTjnCaVh.b8BxpXgd.mx5KTXzlw4k9EywaPToW2bfq2CmfQD9bwHUZNV6PvMoYgk3K70cSvpSoKj92WgDPAL8eHs1HmYkQN313nS_fVeKd48K63JHvNYzR4cqkJz23_.PpIx.my7stlPksfgpKUMgLfXPjo9KFkMmFsUyC50qnqEYXj3_R_L3C7ZNqKoYjpjU3OUOUCTB61qTJZUB6_qXgLEuntVVinVQT7Dxpyfgm_Cxwyfz_sUT8ZkYkyi7dxUjVGtflw.ew1.IMAbNNV4wZJZPqQowJsTj7zuAxP1Nk9aloRLV10YO5Lblq.SNvjmKCJ8BE14Mwi7cY3hPGtrf.TEdWMIzs77semT9X9S9ebdC73hqUyReS58XPcEKlz1_grq8vnuMVGh2UIMutktHSBNVqSxrZuOdN2yiPLw01C33PI_7huRznGG4WBYnJ0tkKE_tJDgWasNivIr0vgWHZzLyjoGL9qwZjJ8Js8n6WNyTJMJ7FaACG4Y1REASG2WuUPWu2osQKutmVSN93hY5t3EDMRMFy38jZ.APURtnDXZEpP6JRe1bZK\",};var a = document.createElement('script');a.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=9535653b9f3278cb';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/?__cf_chl_rt_tk=kbpM5X7ba50puBc4V2DHezLh0Y3sTJ5W1wD66OZ9OH0-1750528721-1.0.1.1-kAL4jdSN_E1befPgdrK6xLbOQobq8l2sqRJLub_1WA4\" + window._cf_chl_opt.cOgUHash);a.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(a);}());</script></body></html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_tool.name)\n",
        "print(get_tool.description)\n",
        "print(get_tool.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L72s3ezn6JHd",
        "outputId": "7306fa38-5093-4cba-ef19-b98a62373f60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests_get\n",
            "A portal to the internet. Use this when you need to get specific\n",
            "    content from a website. Input should be a  url (i.e. https://www.google.com).\n",
            "    The output will be the text response of the GET request.\n",
            "    \n",
            "{'url': {'title': 'Url', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SQL Database Query Tool"
      ],
      "metadata": {
        "id": "6FDz8A7azEvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create a SQLAlchemy engine (example with SQLite, replace with your DB URL)\n",
        "engine = create_engine(\"sqlite:///example.db\")\n",
        "\n",
        "# Initialize the SQLDatabase as a tool\n",
        "sql_tool = SQLDatabase(engine=engine)\n",
        "\n",
        "# Example SQL query\n",
        "query = \"SELECT * FROM users LIMIT 5\"\n",
        "\n",
        "result = sql_tool.run(query) # Use .run() or .invoke() depending on the tool\n",
        "print(result)"
      ],
      "metadata": {
        "id": "HgFfBwQgqJ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sql_tool.name)\n",
        "print(sql_tool.description)\n",
        "print(sql_tool.args)"
      ],
      "metadata": {
        "id": "mFz5ho7y9_ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Python REPL Tool"
      ],
      "metadata": {
        "id": "tgdBq4h9yRjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.tools.python.tool import PythonREPL\n",
        "\n",
        "python_tool = PythonREPL()\n",
        "\n",
        "# Example: Evaluate a simple Python expression\n",
        "result = python_tool.run(\"2 + 2\")\n",
        "print(\"Result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPRNg2Mn0ukX",
        "outputId": "a7123cd3-3357-4618-f5b5-b154b149a3cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Gmail Search Message Tool"
      ],
      "metadata": {
        "id": "mEA9rcYvy9oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())  # Check if 'credentials.json' is here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDajv3KgtIL9",
        "outputId": "cd2285cc-c3a2-4568-831e-a068e32086f4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'example.db', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.gmail import GmailSearch\n",
        "\n",
        "gmail_search_tool = GmailSearch()\n",
        "\n",
        "\n",
        "# Example: Search for recent emails with a keyword\n",
        "result = gmail_search_tool.invoke(\"before:2024/01/01\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "yygJ66EQtikP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gmail_search_tool.name)\n",
        "print(gmail_search_tool.description)\n",
        "print(gmail_search_tool.args)\n"
      ],
      "metadata": {
        "id": "l0aGWeV66l57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}